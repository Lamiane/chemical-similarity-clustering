{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bidict\n",
    "import os\n",
    "import csv\n",
    "import scipy.sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chembls(filename):\n",
    "    result = []\n",
    "    first_line = True\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if first_line:\n",
    "                assert 'CHEMBL' in line\n",
    "                result.append(line.strip())\n",
    "                first_line = False\n",
    "            elif '$$$$' in line:\n",
    "                first_line=True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mapping(all_compounds_file):\n",
    "    mapping = bidict.bidict()\n",
    "    all_chembls = get_chembls(all_compounds_file)        \n",
    "    mapping.update(dict(zip(xrange(len(all_chembls)), all_chembls)))\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_files(path):\n",
    "    return [os.path.join(path,filename) for filename in os.listdir(path) if os.path.isfile(os.path.join(path, filename))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_similarity_matrices(all_compunds_file, folder_with_pairs):\n",
    "    bin_similarity = []\n",
    "    scale_similarity = []\n",
    "    row_ind = []\n",
    "    col_ind = []\n",
    "    \n",
    "    mapping_idx_chembl = get_mapping(all_compunds_file)\n",
    "    n_compunds = len(mapping_idx_chembl)\n",
    "    dict_idx_chemblchembl = \\\n",
    "    dict( [ [int(''.join(c for c in filename if c.isdigit() )), tuple(get_chembls(filename))] \\\n",
    "          for filename in get_all_files(folder_with_pairs) ] )\n",
    "       \n",
    "    ###################################\n",
    "    # # # zapewnij unikalność par # # #\n",
    "    ###################################\n",
    "    non_unique={}\n",
    "    for key in sorted(dict_idx_chemblchembl.keys()):\n",
    "        chembl_i, chembl_j = dict_idx_chemblchembl[key]\n",
    "        for another_key in sorted(dict_idx_chemblchembl.keys()):\n",
    "            if key!=another_key \\\n",
    "            and chembl_i in dict_idx_chemblchembl[another_key]\\\n",
    "            and chembl_j in dict_idx_chemblchembl[another_key]:\n",
    "                new_key = min(key, another_key)\n",
    "                new_value = max(key, another_key)\n",
    "                if new_key not in non_unique.keys():\n",
    "                    non_unique[new_key] = [new_value]\n",
    "                else:\n",
    "                    if non_unique[new_key] is None:\n",
    "                        print non_unique\n",
    "                    non_unique[new_key].append(new_value)\n",
    "    pairs_to_omit = set([item for sublist in non_unique.values() for item in sublist])\n",
    "    ######################\n",
    "    # # # zapewniono # # #\n",
    "    ######################\n",
    "    \n",
    "    \n",
    "    n_omitted = 0\n",
    "    with open('Similarity.csv', 'r') as csvfile:\n",
    "        for pair_number, bin_sim, scale_sim in csv.reader(csvfile, delimiter=','):\n",
    "            if int(pair_number) not in pairs_to_omit:\n",
    "                chembl_i, chembl_j = dict_idx_chemblchembl[int(pair_number)]\n",
    "                chembl_i_idx, chembl_j_idx = mapping_idx_chembl.inv[chembl_i], mapping_idx_chembl.inv[chembl_j]\n",
    "                row_ind.extend([chembl_i_idx, chembl_j_idx])\n",
    "                col_ind.extend([chembl_j_idx, chembl_i_idx])\n",
    "                bin_similarity.extend([int(bin_sim), int(bin_sim)])\n",
    "                scale_similarity.extend([int(scale_sim), int(scale_sim)])\n",
    "            else:\n",
    "                n_omitted += 1\n",
    "    \n",
    "    assert (len(dict_idx_chemblchembl)-n_omitted)*2 == len(bin_similarity)\n",
    "    assert len(bin_similarity)==len(scale_similarity)\n",
    "    assert len(scale_similarity)==len(row_ind)\n",
    "    assert len(row_ind)==len(col_ind)    \n",
    "     \n",
    "    # we want bin similarities to be -1, 1 not 0, 1\n",
    "    bin_similarity = [(-1)**(1-x) for x in bin_similarity]\n",
    "    assert 0 not in scale_similarity\n",
    "    assert 0 not in bin_similarity\n",
    "    \n",
    "    scale_similarity = scipy.sparse.csr_matrix((scale_similarity, (row_ind, col_ind)), shape=(n_compunds, n_compunds))\n",
    "    bin_similarity   = scipy.sparse.csr_matrix((bin_similarity,   (row_ind, col_ind)), shape=(n_compunds, n_compunds))\n",
    "    \n",
    "    assert scale_similarity.nnz == len(row_ind)\n",
    "    assert bin_similarity.nnz == len(row_ind)\n",
    "    \n",
    "    # a compound is always similar to itself\n",
    "    scale_similarity.setdiag(5*np.ones((scale_similarity.shape[0])))\n",
    "    bin_similarity.setdiag(np.ones((bin_similarity.shape[0])))\n",
    "    \n",
    "    assert np.all(scale_similarity.todense() == np.transpose(scale_similarity.todense()))\n",
    "    assert scale_similarity.shape == (n_compunds, n_compunds)\n",
    "    assert np.all(bin_similarity.todense() == np.transpose(bin_similarity.todense()))\n",
    "    assert bin_similarity.shape == (n_compunds, n_compunds)\n",
    "    \n",
    "    assert scale_similarity.nnz == bin_similarity.nnz\n",
    "    assert np.all(scale_similarity.indices == bin_similarity.indices)\n",
    "    assert np.all(scale_similarity.nonzero()[0] == bin_similarity.nonzero()[0])\n",
    "    assert np.all(scale_similarity.nonzero()[1] == bin_similarity.nonzero()[1])\n",
    "    \n",
    "    return bin_similarity, scale_similarity, mapping_idx_chembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_sim, scale_sim, mapping_idx_chembl = load_similarity_matrices('Random_compounds_100.sdf', 'pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958\n",
      "958\n",
      "(958,) (958,)\n",
      "(958,) (958,)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print bin_sim.nnz\n",
    "print scale_sim.nnz\n",
    "\n",
    "a, b = bin_sim.nonzero()[0], bin_sim.nonzero()[1]\n",
    "c, d = scale_sim.nonzero()[0], scale_sim.nonzero()[1]\n",
    "\n",
    "print a.shape, c.shape\n",
    "print b.shape, d.shape\n",
    "\n",
    "print np.all(a==c)\n",
    "print np.all(b==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHEMBL426317', 'CHEMBL2397911']\n",
      "['CHEMBL426317', 'CHEMBL2397911']\n"
     ]
    }
   ],
   "source": [
    "print get_chembls('pairs/Random_pair11.sdf')\n",
    "print get_chembls('pairs/Random_pair267.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_folds():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
