{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import bidict\n",
    "import os\n",
    "import csv\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import load_data\n",
    "from blessings import Terminal\n",
    "term = Terminal()\n",
    "print term.blue('kotek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "all_compounds_file = 'Random_compounds_100.sdf'\n",
    "folder_with_pairs = 'pairs'\n",
    "n_sets = 10\n",
    "\n",
    "possible_compounds = 'possible compounds'\n",
    "pairs_contained = 'pairs contained'\n",
    "probability = 'probability'\n",
    "compounds_contained = 'compounds contained'\n",
    "size = 'size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def clustering_score(clusters, n_omitted):\n",
    "    # chcemy niską wariancję i mało pominiętych par\n",
    "    assert isinstance(clusters, list), 'clusters should be a non-empty list of dictionaries'\n",
    "    assert len(clusters) > 0, 'clusters should be a non-empty list of dictionaries'\n",
    "    assert isinstance(clusters[0], dict), 'clusters should be a non-empty list of dictionaries'\n",
    "    variance = 0\n",
    "    if pairs_contained in clusters[0].keys():\n",
    "        variance = np.var([float(len(cluster[pairs_contained]))/(cluster[probability][1]-cluster[probability][0])\n",
    "                       for cluster in clusters])\n",
    "    elif size in clusters[0].keys():\n",
    "        variance = np.var([float(cluster[size])/(cluster[probability][1]-cluster[probability][0])\n",
    "                       for cluster in clusters])\n",
    "    else:\n",
    "        raise KeyError('either `'+size+'` or `'+pairs_contained+'` must be in clusters')\n",
    "    score = (5./8)*variance + n_omitted\n",
    "    return score, variance # TODO 30 - powinno byc wiecej, bo klastrow bedzie mniej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def agnieszka_folds(all_compunds_file, folder_with_pairs):\n",
    "    best_clusterings = []\n",
    "    best_score = 10**4\n",
    "    scores = []\n",
    "    variances = []\n",
    "    n_ommited_pairs = []\n",
    "    while(True): # many times\n",
    "        bin_sim, _, mapping_idx_chembl = load_data.load_similarity_matrices(all_compunds_file, folder_with_pairs)\n",
    "        bin_sim.setdiag(np.zeros((bin_sim.shape[0]))) # pairs (i,i) are not interesting for us\n",
    "        pairs = zip(bin_sim.nonzero()[0], bin_sim.nonzero()[1])\n",
    "                \n",
    "        random.shuffle(pairs)\n",
    "        clusters = [{possible_compounds:list(mapping_idx_chembl.keys()), pairs_contained:[]} for i in xrange(2)]\n",
    "        clusters[0][probability], clusters[1][probability] = (0.0, 0.9), (0.9, 1.0)\n",
    "        failures = 0\n",
    "        max_failures = len(pairs)\n",
    "        try:\n",
    "            while failures < max_failures:\n",
    "                i, j = pairs.pop() # popping random pair\n",
    "                if i > j:\n",
    "                    continue # saving time\n",
    "                \n",
    "                x = np.random.rand()\n",
    "                for cluster in clusters:  # iterating over clusters to find the chosen one\n",
    "                    if cluster[probability][0] <= x < cluster[probability][1]:  # if the cluster was chosen\n",
    "                        # if pair might go inside\n",
    "                        if i in cluster[possible_compounds] and j in cluster[possible_compounds]:\n",
    "                            failures = 0\n",
    "                            cluster[pairs_contained].append((i,j))\n",
    "                            \n",
    "                            # usun zwiazki i, j z mozliwych w kazdym klastrze poza obecnym\n",
    "                            for c in clusters:\n",
    "                                if i in c[possible_compounds]:\n",
    "                                    c[possible_compounds].remove(i)\n",
    "                                if j in c[possible_compounds]:\n",
    "                                    c[possible_compounds].remove(j)\n",
    "                            cluster[possible_compounds].extend([i, j])\n",
    "                        else: # the cluster was chosen but we cannot fit the pair there\n",
    "                            failures += 1\n",
    "                            pairs.insert(0, (i, j)) # pair goes back to the poll\n",
    "                        break # we've found the chosen one\n",
    "                \n",
    "        except IndexError:  # zbior par jest pusty\n",
    "            print term.green('index error')\n",
    "            pass\n",
    "        finally:\n",
    "            # wyszlismy z while'a, wiec albo mamy wpasowane wszystkie pary albo mielismy 100 porazek\n",
    "            omitted_pairs = len(pairs)\n",
    "            score, variance = clustering_score(clusters, omitted_pairs)\n",
    "            \n",
    "            # TODO: new score needed\n",
    "            print 'score', score\n",
    "            print 'omitted_pairs', omitted_pairs\n",
    "            if score < best_score:\n",
    "                print '\\n'\n",
    "                \n",
    "                best_score = score\n",
    "                best_clusterings.append(clusters)\n",
    "                if len(best_clusterings) > n_sets:\n",
    "                    best_clusterings = best_clusterings[-n_sets:]\n",
    "                scores.append(best_score)\n",
    "                variances.append(variance)\n",
    "                n_ommited_pairs.append(omitted_pairs)\n",
    "                plt.plot(range(len(scores)), scores, c='r')\n",
    "                plt.plot(range(len(variances)), variances, c='g')\n",
    "                plt.plot(range(len(n_ommited_pairs)), n_ommited_pairs, c='b')\n",
    "                plt.title('best score over time')\n",
    "                plt.show()\n",
    "                print \"score\", score, 'variance', variance, 'omitted_pairs', omitted_pairs\n",
    "                print 'wielkości klastrów', [len(cluster[pairs_contained]) for cluster in clusters]\n",
    "                print 'pominietych par', omitted_pairs\n",
    "                print \"#BEST CLUSTERING\\n\", best_clusterings[-1]\n",
    "\n",
    "    \n",
    "            print '_________________________________________________\\n'\n",
    "    \n",
    "    return best_clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "best_clustering = agnieszka_folds(all_compounds_file, folder_with_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def staszek_folds(all_compounds_file, folder_with_pairs):\n",
    "    best_clusterings = []\n",
    "    best_score = 10**4\n",
    "    scores = []\n",
    "    variances = []\n",
    "    n_ommited_pairs = []\n",
    "    \n",
    "    while(True): # many times\n",
    "        bin_sim, _, mapping_idx_chembl = load_data.load_similarity_matrices(all_compounds_file, folder_with_pairs)\n",
    "        bin_sim.setdiag(np.zeros((bin_sim.shape[0]))) # pairs (i,i) are not interesting for us\n",
    "        pairs = zip(bin_sim.nonzero()[0], bin_sim.nonzero()[1])\n",
    "                \n",
    "        random.shuffle(pairs)\n",
    "        clusters = [{compounds_contained:[], size:0} for i in xrange(2)]\n",
    "        clusters[0][probability], clusters[1][probability] = (0.0, 0.9), (0.9, 1.0)\n",
    "        \n",
    "        omitted_pairs = 0\n",
    "        \n",
    "        for compound_index in xrange(0, len(pairs)):\n",
    "            x = np.random.rand()\n",
    "            for cluster in clusters:  # iterating over clusters to find the chosen one\n",
    "                    if cluster[probability][0] <= x < cluster[probability][1]:  # if the cluster was chosen\n",
    "                        cluster[compounds_contained].append(compound_index)\n",
    "                        \n",
    "        for pair in pairs:\n",
    "            i, j = pair\n",
    "            if i > j:\n",
    "                continue # saving time\n",
    "                \n",
    "            contained = False\n",
    "            for cluster in clusters:\n",
    "                if i in cluster[compounds_contained] and j in cluster[compounds_contained]:\n",
    "                    cluster[size] += 1\n",
    "                    contained=True\n",
    "                    break\n",
    "                    \n",
    "            if not contained:    \n",
    "                omitted_pairs += 1\n",
    "\n",
    "        # scoring the clustering found\n",
    "        score, variance = clustering_score(clusters, omitted_pairs)\n",
    "        print 'omitted_pairs', omitted_pairs\n",
    "        print 'score', score\n",
    "        if score < best_score:\n",
    "            print '\\n'\n",
    "\n",
    "            best_score = score\n",
    "            best_clusterings.append(clusters)\n",
    "            if len(best_clusterings) > n_sets:\n",
    "                    best_clusterings = best_clusterings[-n_sets:]\n",
    "            scores.append(best_score)\n",
    "            variances.append(variance)\n",
    "            n_ommited_pairs.append(omitted_pairs)\n",
    "            plt.plot(range(len(scores)), scores, c='r')\n",
    "            plt.plot(range(len(variances)), variances, c='g')\n",
    "            plt.plot(range(len(n_ommited_pairs)), n_ommited_pairs, c='b')\n",
    "            plt.title('best score over time')\n",
    "            plt.show()\n",
    "            print \"score\", score, 'variance', variance, 'omitted_pairs', omitted_pairs\n",
    "            print 'wielkości klastrów', [cluster[size] for cluster in clusters]\n",
    "            print 'pominietych par', omitted_pairs\n",
    "            print \"#BEST CLUSTERING\\n\", best_clusterings[-1]\n",
    "\n",
    "    \n",
    "        print '_________________________________________________\\n'\n",
    "    \n",
    "    return best_clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clustering = staszek_folds(all_compounds_file, folder_with_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
