{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import igraph \n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/nex/Dropbox (GMUM)/ujDOK1/SCFP/mol2vec//mol2vec\")\n",
    "from training_data.datasets import CVBaseChemDataset, BaseChemDataset\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similarity - similarity array\n",
    "# predicted - predicted clusters\n",
    "def stagnieszko_score(similarity, predicted):\n",
    "    assert similarity.shape[0]==predicted.shape[0]\n",
    "    assert similarity.shape[1]==predicted.shape[0]\n",
    "    \n",
    "    thresholds = np.unique(similarity)\n",
    "    known = zip(*similarity.nonzero()) # to nie jest prawda! bo może być znany i mieć 0! reprezentacja!\n",
    "    best = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        score = 0\n",
    "        n_checked = 0\n",
    "        for a, b in known:\n",
    "            n_checked+=1\n",
    "            if a >= b: # dzięki temu sprawdzamy każdą parę jeden raz\n",
    "                continue\n",
    "            if similarity[a, b] >= threshold and predicted[a] == predicted[b]:\n",
    "                score += 1\n",
    "            elif similarity[a, b] < threshold and predicted[a] != predicted[b]:\n",
    "                score += 1\n",
    "        if score > best:\n",
    "            best = score\n",
    "    \n",
    "    # wszystkie pary, które wylądowały w dobrym klastrze przez liczba par (bez par związek sam ze sobą)\n",
    "    # sprawdzić, czy przyjmuje wartości z przedziału [0, 1]\n",
    "    return (2.*best)/n_checked\n",
    "\n",
    "# problem: co jak known is None? ZAPEWNIC ZE SIE NIE ZDARZY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_miu(file_name, seed):\n",
    "    np.random.seed(seed)\n",
    "    miu = scipy.sparse.csr_matrix((n_samples, n_samples))\n",
    "    # diagonal can be done better with identity\n",
    "    for i in xrange(n_samples):\n",
    "        miu[i,i] = 1\n",
    "    for i in xrange(int(0.1*n_samples)):\n",
    "        a = np.random.randint(0, n_samples)\n",
    "        b = np.random.randint(0, n_samples)\n",
    "        if a!=b:\n",
    "            miu[a, b] = np.random.rand()\n",
    "            miu[b, a] = np.random.rand()\n",
    "    return miu\n",
    "# loads miu defining its final structure based on chembls and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_X - samples to be clustered\n",
    "# model , model_params - BaseEstimator, ParameterGrid\n",
    "# miu - array with similarities\n",
    "# threshold - how similar must be two compounds to be similar\n",
    "# seed - seed for experiment\n",
    "def run_experiment(data_X, model, model_params, param_types, miu, seed):    \n",
    "    assert isinstance(model_params, ParameterGrid)\n",
    "    assert isinstance(model, BaseEstimator)\n",
    "    \n",
    "    np.random.seed(seed) # setting the seed for numpy.random methods DO I EVEN USE IT?\n",
    "    n_folds = 3\n",
    "    hyperparams_names = sorted(param_types.keys())\n",
    "    \n",
    "    data_X = data_X.todense()\n",
    "    test_precentage = 0.1  # one tenth will be for final testing TO BE CHANGED\n",
    "    test_start_index = test_precentage*data_X.shape[0]\n",
    "    test_X = data_X[test_start_index:,:]\n",
    "    # can't do so with miu OR CAN?\n",
    "    miu = np.array(miu.todense())\n",
    "    miu_train_val = miu[:test_start_index, :test_start_index]\n",
    "    miu_test = miu[test_start_index:, test_start_index:]\n",
    "    \n",
    "    # createnumpy temp array for this experiment\n",
    "    n_param_sets = len(list(model_params))\n",
    "    n_hyperparams = len(list(model_params)[0].keys())\n",
    "    results = np.ndarray((n_folds*n_param_sets, n_hyperparams+2))\n",
    "    # columns are: all parameters along with their names + fold number + score \n",
    "    \n",
    "    idx = -1\n",
    "    fold = -1\n",
    "    # tu powinien byc jakis podzial najlepszy wyznaczony\n",
    "    skf = StratifiedKFold(data_y[:test_start_index], n_folds=n_folds, shuffle=False, random_state=seed)\n",
    "    for tr_idx, val_idx in skf:\n",
    "        fold += 1\n",
    "        not_val_X = data_X[tr_idx]\n",
    "        val_X = data_X[val_idx]\n",
    "        tr_X = np.vstack((not_val_X, val_X))\n",
    "        miu_val = miu[val_idx]\n",
    "        miu_val = miu_val[:, val_idx]\n",
    "        \n",
    "        for params in list(model_params):\n",
    "            mod = model.set_params(**params)\n",
    "            mod.fit(tr_X)\n",
    "            predictions = mod.predict(val_X)\n",
    "            score = stagnieszko_score(miu_val, predictions)\n",
    "            \n",
    "            # saving results to an array\n",
    "            idx+=1         \n",
    "            temp = [params[key] for key in hyperparams_names]\n",
    "            temp.append(fold)\n",
    "            temp.append(score)\n",
    "            results[idx] = tuple(temp)\n",
    "            \n",
    "    # pandise and save the cross validation results\n",
    "    cols = list(hyperparams_names)  # list() on list to have a copy\n",
    "    cols.append('fold')\n",
    "    cols.append('score')\n",
    "    df = pd.DataFrame(data=results, columns=cols)\n",
    "    for key in param_types.keys():\n",
    "        df[key] = df[key].astype(param_types[key])\n",
    "    \n",
    "    df.to_csv('cv_results')\n",
    "    print df\n",
    "           \n",
    "    # averaging over folds\n",
    "    df2 = df.groupby(hyperparams_names).mean()\n",
    "    # choosing model that performed best\n",
    "    df3 = df2[df2['score'] == df2['score'].max()]\n",
    "    print df3\n",
    "    best_params = dict(zip(hyperparams_names, df3.index.tolist()[0]))\n",
    "    print 'best params are', best_params\n",
    "\n",
    "    # training final model\n",
    "    final_model = model.set_params(**best_params)\n",
    "    final_model.fit(data_X)\n",
    "    preds = final_model.predict(test_X)\n",
    "    final_score = stagnieszko_score(miu_test, preds)\n",
    "    \n",
    "    cols = list(hyperparams_names)\n",
    "    final_results = [best_params[key] for key in cols]\n",
    "    cols.append('score')\n",
    "    final_results.append(final_score)\n",
    "    final_df = pd.DataFrame.from_items(zip(cols, [np.array([item]) for item in final_results]))\n",
    "    print final_df\n",
    "    final_df.to_csv('final_results')\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nex/Libraries/anaconda/lib/python2.7/site-packages/scipy/sparse/compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "/home/nex/Libraries/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/nex/Libraries/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/nex/Libraries/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:32: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_iter  n_clusters  fold     score\n",
      "0        100           4   0.0  0.000000\n",
      "1        100           5   0.0  0.000000\n",
      "2        200           4   0.0  0.000000\n",
      "3        200           5   0.0  0.000000\n",
      "4        100           4   1.0  0.011173\n",
      "5        100           5   1.0  0.011173\n",
      "6        200           4   1.0  0.011173\n",
      "7        200           5   1.0  0.011173\n",
      "8        100           4   2.0  0.000000\n",
      "9        100           5   2.0  0.000000\n",
      "10       200           4   2.0  0.000000\n",
      "11       200           5   2.0  0.000000\n",
      "                     fold     score\n",
      "max_iter n_clusters                \n",
      "100      4            1.0  0.003724\n",
      "         5            1.0  0.003724\n",
      "200      4            1.0  0.003724\n",
      "         5            1.0  0.003724\n",
      "best params are {'max_iter': 100, 'n_clusters': 4}\n",
      "   max_iter  n_clusters     score\n",
      "0       100           4  0.090281\n"
     ]
    }
   ],
   "source": [
    "(data_X, data_y), _ = BaseChemDataset(representation=\"KR\", compound='5-HT1a', valid_size=0.0).get_data()\n",
    "n_samples = data_X.shape[0]\n",
    "model = sklearn.cluster.KMeans()\n",
    "params = ParameterGrid({'n_clusters':[4, 5], 'max_iter':[100, 200]})\n",
    "param_types = {'n_clusters': 'int', 'max_iter':'int'}\n",
    "\n",
    "seed = 43\n",
    "np.random.seed(seed)\n",
    "\n",
    "miu = load_miu('miu.libsvm or any other format please', seed)\n",
    "threshold = .5 # what do we do with thresholding?\n",
    "\n",
    "df = run_experiment(data_X, model, params, param_types, miu, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5321\n"
     ]
    }
   ],
   "source": [
    "print n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e35bdf5301a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df\n",
    "hn = ['max_iter', 'n_clusters']\n",
    "df2 = df.groupby(hn).mean()\n",
    "# choosing model that performed best\n",
    "df3 = df2[df2['score'] == df2['score'].max()]\n",
    "print dict(zip(hn, df3.index.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print miu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
